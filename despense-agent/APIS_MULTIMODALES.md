# üîå APIs para Funcionalidades Multimodales

## üìã Estado Actual

‚úÖ **IMPLEMENTADO**: Las herramientas `transcribir_audio` y `procesar_imagen` est√°n **completamente implementadas** usando APIs reales de OpenAI:

- `transcribir_audio`: Usa OpenAI Whisper API
- `procesar_imagen`: Usa OpenAI Vision API (GPT-4o-mini)

Ambas herramientas incluyen:

- ‚úÖ Validaci√≥n de archivos (existencia, formato, tama√±o)
- ‚úÖ Manejo de errores robusto
- ‚úÖ Mensajes de error descriptivos
- ‚úÖ L√≠mites de tama√±o de archivo

## üé§ Transcripci√≥n de Audio

### Opci√≥n 1: OpenAI Whisper API (Recomendado)

**Ventajas:**

- Alta precisi√≥n
- Soporta m√∫ltiples idiomas
- Mismo proveedor que el LLM (OpenAI)
- F√°cil integraci√≥n

**Configuraci√≥n necesaria:**

```python
# Ya tienes OPENAI_API_KEY configurada ‚úÖ
# No necesitas API key adicional
```

**Implementaci√≥n:**

```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def transcribir_audio(audio_file_path: str) -> str:
    with open(audio_file_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="es"  # Opcional: especificar idioma
        )
    return f"El usuario dijo: '{transcript.text}'"
```

**Costos:**

- $0.006 por minuto de audio
- Muy econ√≥mico para uso personal

**Dependencias adicionales:**

```bash
# Ya est√° incluido en openai>=1.109.1 (que ya tienes instalado)
# No necesitas instalar nada adicional
```

---

### Opci√≥n 2: Google Cloud Speech-to-Text

**Ventajas:**

- Muy preciso
- Soporte para m√∫ltiples idiomas
- Buena para producci√≥n a escala

**Configuraci√≥n necesaria:**

```bash
# Instalar SDK
pip install google-cloud-speech

# Configurar credenciales
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
```

**Implementaci√≥n:**

```python
from google.cloud import speech

def transcribir_audio(audio_file_path: str) -> str:
    client = speech.SpeechClient()
  
    with open(audio_file_path, "rb") as audio_file:
        content = audio_file.read()
  
    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="es-ES",
    )
  
    response = client.recognize(config=config, audio=audio)
  
    transcript = " ".join([result.alternatives[0].transcript 
                          for result in response.results])
    return f"El usuario dijo: '{transcript}'"
```

**Costos:**

- Primeros 60 minutos/mes: GRATIS
- Despu√©s: $0.006 por minuto

---

## üñºÔ∏è Procesamiento de Im√°genes

### Opci√≥n 1: OpenAI Vision API (GPT-4 Vision) (Recomendado)

**Ventajas:**

- Integraci√≥n perfecta con el LLM actual
- Entiende contexto complejo
- Puede extraer informaci√≥n estructurada
- Mismo proveedor (OpenAI)

**Configuraci√≥n necesaria:**

```python
# Ya tienes OPENAI_API_KEY configurada ‚úÖ
# No necesitas API key adicional
```

**Implementaci√≥n:**

```python
from openai import OpenAI
import base64

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def procesar_imagen(image_file_path: str) -> str:
    # Leer y codificar la imagen
    with open(image_file_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode('utf-8')
  
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # o "gpt-4o" para mejor precisi√≥n
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": """Analiza esta imagen de una despensa o compra. 
                        Identifica los productos y genera un mensaje estructurado 
                        para actualizar el inventario. Formato: 
                        "Compra de [producto] [cantidad], establecer a ALTO"
                        Si hay m√∫ltiples productos, lista cada uno."""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        max_tokens=300
    )
  
    return response.choices[0].message.content
```

**Costos:**

- GPT-4o-mini: $0.15 por 1M tokens de entrada, $0.60 por 1M tokens de salida
- GPT-4o: $2.50 por 1M tokens de entrada, $10.00 por 1M tokens de salida
- Una imagen t√≠pica: ~85 tokens

**Dependencias adicionales:**

```bash
# Ya est√° incluido en openai>=1.109.1
# No necesitas instalar nada adicional
```

---

### Opci√≥n 2: Google Cloud Vision API

**Ventajas:**

- Muy preciso para detecci√≥n de objetos
- Buena para reconocimiento de productos
- Escalable

**Configuraci√≥n necesaria:**

```bash
# Instalar SDK
pip install google-cloud-vision

# Configurar credenciales
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
```

**Implementaci√≥n:**

```python
from google.cloud import vision

def procesar_imagen(image_file_path: str) -> str:
    client = vision.ImageAnnotatorClient()
  
    with open(image_file_path, "rb") as image_file:
        content = image_file.read()
  
    image = vision.Image(content=content)
  
    # Detectar objetos y texto
    response = client.label_detection(image=image)
    labels = [label.description for label in response.label_annotations]
  
    # Usar el LLM para estructurar la informaci√≥n
    # (combinar con OpenAI para mejor resultado)
    productos_detectados = ", ".join(labels[:5])  # Top 5
  
    return f"Productos detectados en imagen: {productos_detectados}. Actualizar inventario seg√∫n necesidad."
```

**Costos:**

- Primeras 1,000 unidades/mes: GRATIS
- Despu√©s: $1.50 por 1,000 unidades

---

## üöÄ Recomendaci√≥n para Implementaci√≥n

### Para MVP/Producci√≥n Inicial:

**Usar OpenAI para ambas funcionalidades:**

- ‚úÖ Ya tienes la API key configurada
- ‚úÖ No necesitas credenciales adicionales
- ‚úÖ Integraci√≥n simple
- ‚úÖ Costos razonables
- ‚úÖ Alta calidad

### Pasos para Implementar:

1. **Actualizar `transcribir_audio`:**

   ```python
   # Reemplazar la simulaci√≥n con llamada real a OpenAI Whisper
   ```
2. **Actualizar `procesar_imagen`:**

   ```python
   # Reemplazar la simulaci√≥n con llamada real a OpenAI Vision
   ```
3. **Manejo de errores:**

   ```python
   # Agregar try/except para manejar errores de API
   # Validar que el archivo existe y es v√°lido
   ```
4. **Optimizaci√≥n:**

   ```python
   # Cachear resultados si el mismo archivo se procesa m√∫ltiples veces
   # Validar tipos de archivo antes de procesar
   ```

## üìù Checklist de Configuraci√≥n

- [X] OPENAI_API_KEY configurada (ya tienes esto)
- [ ] Implementar `transcribir_audio` con OpenAI Whisper
- [ ] Implementar `procesar_imagen` con OpenAI Vision
- [ ] Agregar validaci√≥n de tipos de archivo
- [ ] Agregar manejo de errores
- [ ] Probar con archivos reales
- [ ] Documentar l√≠mites de tama√±o de archivo

## ‚ö†Ô∏è Notas Importantes

1. **L√≠mites de tama√±o:**

   - OpenAI Whisper: m√°ximo 25 MB por archivo
   - OpenAI Vision: im√°genes deben ser < 20 MB
2. **Formatos soportados:**

   - Audio: mp3, mp4, mpeg, mpga, m4a, wav, webm
   - Imagen: jpg, jpeg, png, gif, webp
3. **Costos estimados:**

   - 100 transcripciones de 1 minuto: ~$0.60
   - 100 an√°lisis de im√°genes: ~$0.01-0.02

## üîÑ Migraci√≥n desde Simulaci√≥n

Para migrar de la simulaci√≥n actual a implementaci√≥n real:

1. Mantener la misma firma de funci√≥n
2. Reemplazar la l√≥gica de simulaci√≥n con llamadas API reales
3. Mantener el mismo formato de retorno
4. El resto del c√≥digo no necesita cambios

El c√≥digo est√° dise√±ado para que esta migraci√≥n sea transparente.
