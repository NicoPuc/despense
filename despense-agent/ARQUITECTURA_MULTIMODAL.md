# ğŸ—ï¸ Arquitectura Multimodal del Agente de Despensa

## ğŸ“‹ Resumen Ejecutivo

Este documento explica cÃ³mo el LLM decide la ruta de ejecuciÃ³n en el Agente de Despensa cuando recibe diferentes tipos de entrada: texto puro o archivos multimedia (audio/imagen).

## ğŸ”„ Flujo de Decisiones del LLM

### Caso A: Entrada Solo de Texto

**Ejemplo:** `"Â¿QuÃ© me falta?"`

```
1. Usuario envÃ­a: "Â¿QuÃ© me falta?"
   â†“
2. agent_node recibe el estado:
   - messages: [HumanMessage("Â¿QuÃ© me falta?")]
   - user_input: "Â¿QuÃ© me falta?"
   - media_file_path: None
   â†“
3. El LLM analiza el mensaje con el system_prompt:
   - Detecta que es una CONSULTA
   - No hay archivo multimedia, asÃ­ que salta el paso de procesamiento
   â†“
4. El LLM decide usar: consultar_despensa
   - Genera un tool_call con item_name apropiado
   â†“
5. should_continue() detecta tool_calls â†’ retorna "tools"
   â†“
6. ToolNode ejecuta: consultar_despensa
   â†“
7. Vuelve a agent_node con el resultado
   â†“
8. El LLM genera respuesta final usando el resultado de la herramienta
   â†“
9. should_continue() no detecta mÃ¡s tool_calls â†’ retorna "end"
   â†“
10. FIN: Respuesta al usuario
```

**Flujo Visual:**
```
Usuario â†’ agent_node â†’ [LLM decide: consultar_despensa] â†’ tools â†’ agent_node â†’ [LLM genera respuesta] â†’ END
```

---

### Caso B: Entrada con Archivo Multimedia

**Ejemplo:** `media_file_path = "audio_compre_pan.wav"`

```
1. Usuario envÃ­a archivo: "audio_compre_pan.wav"
   â†“
2. agent_node recibe el estado:
   - messages: [HumanMessage("El usuario ha enviado un archivo audio: audio_compre_pan.wav")]
   - user_input: ""
   - media_file_path: "audio_compre_pan.wav"
   â†“
3. El LLM analiza el estado:
   - Detecta que media_file_path NO es None
   - Detecta que la extensiÃ³n es .wav (audio)
   - El system_prompt indica: "Si hay media_file_path, PRIMERO procesa el archivo"
   â†“
4. El LLM decide usar: transcribir_audio(audio_file_path="audio_compre_pan.wav")
   - Genera un tool_call para transcribir_audio
   â†“
5. should_continue() detecta tool_calls â†’ retorna "tools"
   â†“
6. ToolNode ejecuta: transcribir_audio
   - Retorna: "El usuario dijo: 'ComprÃ© pan'"
   â†“
7. Vuelve a agent_node con el resultado de la transcripciÃ³n
   â†“
8. El LLM analiza el texto transcrito: "El usuario dijo: 'ComprÃ© pan'"
   - Detecta que es una ACTUALIZACIÃ“N
   - Identifica: item="pan", acciÃ³n="ComprÃ©" â†’ estado="ALTO"
   â†“
9. El LLM decide usar: actualizar_despensa(item_name="pan", new_status="ALTO")
   - Genera un nuevo tool_call
   â†“
10. should_continue() detecta tool_calls â†’ retorna "tools"
   â†“
11. ToolNode ejecuta: actualizar_despensa
    - Actualiza DESPENSA_DB["pan"] = "ALTO"
    - Retorna: "âœ… Actualizado: 'pan' ahora tiene estado 'ALTO'"
   â†“
12. Vuelve a agent_node con el resultado de la actualizaciÃ³n
   â†“
13. El LLM genera respuesta final confirmando la actualizaciÃ³n
   â†“
14. should_continue() no detecta mÃ¡s tool_calls â†’ retorna "end"
   â†“
15. FIN: Respuesta al usuario confirmando la actualizaciÃ³n
```

**Flujo Visual:**
```
Usuario (audio) â†’ agent_node â†’ [LLM decide: transcribir_audio] 
    â†’ tools â†’ agent_node â†’ [LLM analiza transcripciÃ³n] 
    â†’ [LLM decide: actualizar_despensa] 
    â†’ tools â†’ agent_node â†’ [LLM genera respuesta] â†’ END
```

---

## ğŸ§  LÃ³gica de DecisiÃ³n del LLM

### 1. **DetecciÃ³n de Tipo de Entrada**

El `agent_node` determina quÃ© herramientas estÃ¡n disponibles:

```python
if media_file_path:
    file_ext = os.path.splitext(media_file_path)[1].lower()
    if file_ext in ['.wav', '.mp3', ...]:  # Audio
        all_tools = [transcribir_audio, consultar_despensa, actualizar_despensa]
    elif file_ext in ['.jpg', '.png', ...]:  # Imagen
        all_tools = [procesar_imagen, consultar_despensa, actualizar_despensa]
else:
    all_tools = [consultar_despensa, actualizar_despensa]  # Solo texto
```

### 2. **System Prompt GuÃ­a la DecisiÃ³n**

El `system_prompt` instruye al LLM:

```
"Si el usuario envÃ­a un archivo multimedia:
   - PRIMERO debes usar 'transcribir_audio' o 'procesar_imagen'
   - Luego, usa el resultado para decidir la siguiente acciÃ³n"
```

### 3. **Procesamiento en Cascada**

El LLM procesa en mÃºltiples pasos:

1. **Paso 1 (si hay multimedia):** Procesar archivo â†’ obtener texto
2. **Paso 2:** Analizar texto â†’ decidir acciÃ³n (consultar/actualizar)
3. **Paso 3:** Ejecutar acciÃ³n â†’ obtener resultado
4. **Paso 4:** Generar respuesta final

### 4. **Enrutamiento Condicional**

El `should_continue()` decide el flujo:

- Si hay `tool_calls` â†’ ir a `tools`
- Si no hay `tool_calls` â†’ ir a `END`

## ğŸ“Š ComparaciÃ³n de Flujos

| Aspecto | Solo Texto | Con Multimedia |
|---------|-----------|----------------|
| **Pasos iniciales** | 1 (anÃ¡lisis directo) | 2 (procesar archivo + anÃ¡lisis) |
| **Herramientas disponibles** | 2 (consultar, actualizar) | 3-4 (multimodal + consultar + actualizar) |
| **Tool calls tÃ­picos** | 1 | 2 (procesar + acciÃ³n) |
| **Tiempo de procesamiento** | MÃ¡s rÃ¡pido | MÃ¡s lento (mÃºltiples iteraciones) |

## ğŸ”‘ Puntos Clave

1. **El LLM decide dinÃ¡micamente** quÃ© herramientas usar basÃ¡ndose en:
   - Presencia de `media_file_path`
   - Tipo de archivo (extensiÃ³n)
   - Contenido del mensaje/texto procesado

2. **El flujo es iterativo**: El agente puede hacer mÃºltiples llamadas a herramientas en secuencia:
   - Primero: procesar multimedia
   - Segundo: ejecutar acciÃ³n (consultar/actualizar)
   - Tercero: generar respuesta

3. **El estado se mantiene entre iteraciones**: 
   - `messages` acumula todo el historial
   - `media_file_path` se mantiene hasta que se procesa
   - Cada iteraciÃ³n del `agent_node` tiene contexto completo

4. **El enrutador (`should_continue`) es simple pero efectivo**:
   - Solo verifica si hay `tool_calls`
   - No necesita lÃ³gica compleja porque el LLM ya decidiÃ³ quÃ© hacer

## ğŸš€ Extensibilidad

Para agregar mÃ¡s tipos de multimedia:

1. Agregar nueva herramienta (ej: `procesar_video`)
2. Actualizar detecciÃ³n de tipo de archivo en `agent_node`
3. Agregar al `ToolNode` en `create_despensa_graph()`
4. Actualizar `system_prompt` con instrucciones

El sistema es modular y fÃ¡cil de extender.

